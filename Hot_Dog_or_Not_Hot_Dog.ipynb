{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COPY 2 of Copy of Kang_Tang_Fernandez_ TBD: Hot Dog or Not Hot Dog",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "yFwKrxE38t9S"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juliakay/ml-fun/blob/master/Hot_Dog_or_Not_Hot_Dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFwKrxE38t9S",
        "colab_type": "text"
      },
      "source": [
        "#### Copyright 2019 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpcrMDk48nqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTZOeKjw8waH",
        "colab_type": "text"
      },
      "source": [
        "# Hot Dog or Not Hot Dog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-NVlAzG81L-",
        "colab_type": "text"
      },
      "source": [
        "There are very few more important questions in life than \"[Hot dog or not hot dog?](https://www.youtube.com/watch?v=ACmydtFDTGs)\". For this challenge you will be tasked with creating a machine learning model that can take an input image and determine if the image is of a hot dog or not a hot dog.\n",
        "\n",
        "Train your model with the [Kaggle Hot Dog/Not Hot Dog](https://www.kaggle.com/dansbecker/hot-dog-not-hot-dog/data) data set. Feel free to [do some background research](https://medium.com/@timanglade/how-hbos-silicon-valley-built-not-hotdog-with-mobile-tensorflow-keras-react-native-ef03260747f3) on the topic.\n",
        "\n",
        "We have looked a regression, classification, and clustering models. We have used the Scikit Learn, TensorFlow, and Keras toolkits. Feel free to use the model and toolkit that you feel is the most appropriate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i51MLWdUny-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('hot-dog-not-hot-dog.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()\n",
        "\n",
        "import glob\n",
        "train_dog_images = glob.glob('train/hot_dog' + '/*.jpg')\n",
        "\n",
        "\n",
        "import IPython.display as display\n",
        "# display.display(display.Image(images[0]))\n",
        "\n",
        "# for i in train_dog_images:\n",
        "#   display.display(display.Image(i))\n",
        "\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "# session = tf.Session()\n",
        "\n",
        "def preprocess_image(image):\n",
        "  # encode image to tensor\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  \n",
        "  # resize image\n",
        "  image = tf.image.resize_images(image, [150, 150])\n",
        "  \n",
        "  # normalize\n",
        "  image /= 255.0\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "  image = tf.read_file(path)\n",
        "  return preprocess_image(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml7iufnX8zOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzip files\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('hot-dog-not-hot-dog.zip', 'r')\n",
        "zip_ref.extractall('./')\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VVMjoG5UNM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image processing\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def preprocess_image(image):\n",
        "  # encode image to tensor\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  \n",
        "  # resize image\n",
        "  image = tf.image.resize_images(image, [160, 160])\n",
        "  \n",
        "  # normalize\n",
        "  image /= 255.0\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "  image = tf.read_file(path)\n",
        "  return preprocess_image(image)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UUxvpwPsmVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab all file names\n",
        "import glob\n",
        "train_dog_images = glob.glob('train/hot_dog' + '/*.jpg')\n",
        "train_notdog_images = glob.glob('train/not_hot_dog' + '/*.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ecXmFTKixxI",
        "colab_type": "code",
        "outputId": "4896eb83-594d-4a7b-a455-54606b08fa03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Dog training data\n",
        "# unpack all images from train/hot dog folder \n",
        "import numpy as np\n",
        "\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(train_dog_images)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# initialize dog labels\n",
        "is_dog = np.ones(len(train_dog_images), dtype=int)\n",
        "\n",
        "is_dog_label_ds = tf.data.Dataset.from_tensor_slices(is_dog)\n",
        "# print(label_ds)\n",
        "\n",
        "# create dataset with image and labels\n",
        "image_label_ds = tf.data.Dataset.zip((image_ds, is_dog_label_ds))\n",
        "\n",
        "print('image shape: ', image_label_ds.output_shapes[0])\n",
        "print('label shape: ', image_label_ds.output_shapes[1])\n",
        "print('types: ', image_label_ds.output_types)\n",
        "print()\n",
        "print(image_label_ds)\n",
        "\n",
        "# plot figures\n",
        "# plt.figure(figsize=(8,8))\n",
        "# for n,image in enumerate(image_ds.take(4)):\n",
        "#   plt.subplot(2,2,n+1)\n",
        "#   plt.imshow(image)\n",
        "#   plt.grid(False)\n",
        "#   plt.xticks([])\n",
        "#   plt.yticks([])\n",
        "# #   plt.xlabel(caption_image(train[n]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-6cc48020fbc4>:15: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_shapes(dataset)`.\n",
            "image shape:  (160, 160, 3)\n",
            "label shape:  ()\n",
            "WARNING:tensorflow:From <ipython-input-9-6cc48020fbc4>:17: DatasetV1.output_types (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.data.get_output_types(dataset)`.\n",
            "types:  (tf.float32, tf.int64)\n",
            "\n",
            "<DatasetV1Adapter shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYaKuQ0UtE8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Not dog training data\n",
        "# unpack all images from train/not hot dog folder\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(train_notdog_images)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# initialize dog labels\n",
        "is_notdog = np.zeros(len(train_notdog_images), dtype=int)\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(is_notdog)\n",
        "image_label_ds_not = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "final_train = image_label_ds.concatenate(image_label_ds_not)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZpgEWo-pBx5",
        "colab_type": "code",
        "outputId": "4f271d6c-a8e5-4fbb-c151-252469f61b1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
        "# completely shuffled.\n",
        "image_count = len(train_dog_images) + len(train_notdog_images)\n",
        "ds = final_train.shuffle(buffer_size=image_count)\n",
        "ds = ds.repeat()\n",
        "ds = ds.batch(32)\n",
        "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
        "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
        "ds\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: ((?, 160, 160, 3), (?,)), types: (tf.float32, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcQtPO8Xpoym",
        "colab_type": "code",
        "outputId": "48b41120-b384-4f16-d6e8-f1e72d98c794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "mobile_net = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3), include_top=False)\n",
        "mobile_net.trainable=False"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-FBCM_YrdGi",
        "colab_type": "code",
        "outputId": "478d2c2d-054f-498c-af2b-a3feec6f0e2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#This model expects its input to be normalized to the [-1,1] range:\n",
        "\n",
        "def change_range(image,label):\n",
        "  return 2*image-1, label\n",
        "\n",
        "keras_ds = ds.map(change_range)\n",
        "\n",
        "# The dataset may take a few seconds to start, as it fills its shuffle buffer.\n",
        "image_batch, label_batch = next(iter(keras_ds))\n",
        "\n",
        "feature_map_batch = mobile_net(image_batch)\n",
        "print(feature_map_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 5, 5, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RhYu-RrtyEg",
        "colab_type": "code",
        "outputId": "61fb9df2-9eef-43d1-e868-ff2a7a4d86e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  mobile_net,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(image_count)])\n",
        "\n",
        "logit_batch = model(image_batch).numpy()\n",
        "\n",
        "print(\"min logit:\", logit_batch.min())\n",
        "print(\"max logit:\", logit_batch.max())\n",
        "print()\n",
        "\n",
        "print(\"Shape:\", logit_batch.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "min logit: -3.5233228\n",
            "max logit: 4.312913\n",
            "\n",
            "Shape: (32, 498)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw8BiAMQuNti",
        "colab_type": "code",
        "outputId": "7a071c2b-6646-48ef-9ba1-a9a7c9ebe8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])\n",
        "len(model.trainable_variables) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3LzuZODuPLR",
        "colab_type": "code",
        "outputId": "1e8beb2c-d54a-4dde-cacc-c519d52f50ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mobilenetv2_1.00_160 (Model) (None, 5, 5, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 498)               637938    \n",
            "=================================================================\n",
            "Total params: 2,895,922\n",
            "Trainable params: 637,938\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3SX5ihluzbz",
        "colab_type": "code",
        "outputId": "022bd3a7-07dc-4893-ceb2-69c88155c89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "model.fit(ds, epochs=10, steps_per_epoch=3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "3/3 [==============================] - 10s 3s/step - loss: 15.6126 - acc: 0.0104\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 3.8580 - acc: 0.3333\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 1.2478 - acc: 0.4375\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.7065 - acc: 0.5521\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 6s 2s/step - loss: 0.6932 - acc: 0.4896\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6959 - acc: 0.4792\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6932 - acc: 0.5833\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6900 - acc: 0.5417\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6932 - acc: 0.5417\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 7s 2s/step - loss: 0.6932 - acc: 0.5208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6097936da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM9fBfmTv4ql",
        "colab_type": "code",
        "outputId": "9aa870f3-a578-462e-e067-84ba7f48b40e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#TESTING-DOG\n",
        "import numpy as np\n",
        "test_dog_images = glob.glob('test/hot_dog' + '/*.jpg')\n",
        "# unpack all images from test/hot dog folder\n",
        "path_ds = tf.data.Dataset.from_tensor_slices(test_dog_images)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# initialize dog labels\n",
        "is_dog = np.ones(len(test_dog_images), dtype=int)\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(is_dog)\n",
        "\n",
        "# print(label_ds)\n",
        "# create dataset with image and labels\n",
        "image_label_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "\n",
        "#TESTING-NOT DOG \n",
        "test_not_dog_images = glob.glob('test/not_hot_dog' + '/*.jpg')\n",
        "\n",
        "#unpack all images from test/not hot dog folder \n",
        "path_ds = tf.data.Dataset.from_tensor_slices(test_not_dog_images)\n",
        "image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "#initialize not dog labels \n",
        "is_notdog = np.zeros(len(test_not_dog_images), dtype=int)\n",
        "label_ds = tf.data.Dataset.from_tensor_slices(is_notdog)\n",
        "image_label_ds_not = tf.data.Dataset.zip((image_ds, label_ds))\n",
        "\n",
        "final_test = image_label_ds.concatenate(image_label_ds_not)\n",
        "\n",
        "print('image shape: ', final_test.output_shapes[0])\n",
        "print('label shape: ', final_test.output_shapes[1])\n",
        "print('types: ', final_test.output_types)\n",
        "print()\n",
        "print(final_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image shape:  (160, 160, 3)\n",
            "label shape:  ()\n",
            "types:  (tf.float32, tf.int64)\n",
            "\n",
            "<DatasetV1Adapter shapes: ((160, 160, 3), ()), types: (tf.float32, tf.int64)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHxkuZGuy8eN",
        "colab_type": "code",
        "outputId": "539a79c7-2922-4c68-b03a-b9c1943f3ce9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "model.predict(final_test, steps=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-a051b19efd0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m           callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m     \u001b[0;31m# Case 3: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(x, y, sample_weights)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;31m# 1, 2, or 3-tuples from generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=unused-argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;31m# Validate and standardize user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m     inputs, _, _ = self._standardize_user_data(\n\u001b[0;32m-> 1281\u001b[0;31m         x, extract_tensors_from_dataset=True)\n\u001b[0m\u001b[1;32m   1282\u001b[0m     \u001b[0;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m     \u001b[0;31m# at this point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    374\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected mobilenetv2_1.00_160_input to have 4 dimensions, but got array with shape (160, 160, 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrr5aLM10kRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}